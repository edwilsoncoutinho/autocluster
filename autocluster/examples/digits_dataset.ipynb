{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# change working directory, run this cell once\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will demonstrate an example on how to use the ``AutoCluster`` class for clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will be using sample datasets in sklearn\n",
    "from sklearn import datasets\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# autocluster functionalities\n",
    "from autocluster import AutoCluster\n",
    "from evaluators import get_evaluator\n",
    "from utils.metafeatures import MetafeatureMapper\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sklearn digits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_df = pd.DataFrame(datasets.load_digits()['data'])\n",
    "digits_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that we are converting the dataset from ``numpy`` format to ``pandas DataFrame`` format. \n",
    "- This is because the ``AutoCluster.fit()`` function only accepts ``DataFrame`` format as input.\n",
    "- There are 64 columns in this dataset, named ``0``, ``1``, ``2`` ... and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of this dataframe is {}\".format(digits_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding an optimal clustering model using Bayesian Optimization (SMAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = AutoCluster()\n",
    "fit_params = {\n",
    "    \"df\": digits_df, \n",
    "    \"cluster_alg_ls\": [\n",
    "        'KMeans', 'GaussianMixture', 'MiniBatchKMeans'\n",
    "    ], \n",
    "    \"dim_reduction_alg_ls\": [\n",
    "        'PCA', 'IncrementalPCA', \n",
    "        'KernelPCA', 'FastICA', 'TruncatedSVD', 'NullModel'\n",
    "    ],\n",
    "    \"optimizer\": 'smac',\n",
    "    \"n_evaluations\": 100,\n",
    "    \"run_obj\": 'quality',\n",
    "    \"seed\": 27,\n",
    "    \"cutoff_time\": 50,\n",
    "    \"preprocess_dict\": {\n",
    "        \"numeric_cols\": list(range(64)),\n",
    "        \"categorical_cols\": [],\n",
    "        \"ordinal_cols\": [],\n",
    "        \"y_col\": []\n",
    "    },\n",
    "    \"evaluator\": get_evaluator(evaluator_ls = ['silhouetteScore', \n",
    "                                               'daviesBouldinScore', \n",
    "                                               'calinskiHarabaszScore'], \n",
    "                               weights = [1, 1, 1], \n",
    "                               clustering_num = None, \n",
    "                               min_proportion = .01, \n",
    "                               min_relative_proportion='default'),\n",
    "    \"n_folds\": 5,\n",
    "    \"warmstart\": False\n",
    "}\n",
    "result_dict = cluster.fit(**fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot going on here, let's talk about some of the parameters used in the example above:\n",
    "- ``cluster_alg_ls``: This is the list of possible clustering algorithms to include within the search space.\n",
    "- ``dim_reduction_alg_ls``: This is the list of possible dimension reduction algorithms to include within the search space. Dimension reduction is performed **before** the clustering step. \n",
    "- ``optimizer``: There are two options for this, ``\"smac\"`` or ``\"random\"``. ``\"smac\"`` does Bayesian Optimization using the SMAC library, while ``\"random\"`` just performs random search optimization.\n",
    "- ``n_evaluations``: number of iterations to run, generally the larger the better.\n",
    "- ``cutoff_time``: If evaluating a certain configuration takes longer than this value (in seconds), it will be terminated.\n",
    "- ``preprocess_dict``: This is important, ``AutoCluster.fit()`` uses this dictionary to preprocess the dataset. For instance, categorical columns will be one hot encoded, while ordinal columns will encoded as integers. \n",
    "- ``evaluator``: This is important, it tells ``AutoCluster.fit()`` how to evaluate a clustering result. \n",
    "    - ``evaluator_ls``: list of metric to include in a linear combination. Choices available are ``[\"silhouetteScore\", \"daviesBouldinScore\", \"calinskiHarabaszScore\"]``.\n",
    "    - ``weights``: how much weights to use for each metric in the linear combination.\n",
    "    - ``clustering_num``: A tuple is expected. If clustering result has n_clusters outside this specified range, ``float(inf)`` will be returned from evaluator.\n",
    "    - ``min_proportion``: The proportion of points in each cluster must be at least this value.\n",
    "    - ``min_relative_proportion``: The ratio of number points in the smallest cluster to the number of points in the largest cluster must be at least this value. By using ``'default'``, ``min_relative_proportion`` will be set to `` 5 * min_proportion``.\n",
    "- ``warmstart``: Whether or not to use warmstart, examples will be shown below on how to use this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cluster.predict(digits_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_dict[\"optimal_cfg\"])\n",
    "print(Counter(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spia2019]",
   "language": "python",
   "name": "conda-env-spia2019-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
